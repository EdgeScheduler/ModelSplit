def @main(%data_0: Tensor[(15, 3, 224, 224), float32], %features.0.weight: Tensor[(96, 3, 7, 7), float32], %features.0.bias: Tensor[(96), float32], %features.3.squeeze.weight: Tensor[(16, 96, 1, 1), float32], %features.3.squeeze.bias: Tensor[(16), float32], %features.3.expand1x1.weight: Tensor[(64, 16, 1, 1), float32], %features.3.expand1x1.bias: Tensor[(64), float32], %features.3.expand3x3.weight: Tensor[(64, 16, 3, 3), float32], %features.3.expand3x3.bias: Tensor[(64), float32], %features.4.squeeze.weight: Tensor[(16, 128, 1, 1), float32], %features.4.squeeze.bias: Tensor[(16), float32], %features.4.expand1x1.weight: Tensor[(64, 16, 1, 1), float32], %features.4.expand1x1.bias: Tensor[(64), float32], %features.4.expand3x3.weight: Tensor[(64, 16, 3, 3), float32], %features.4.expand3x3.bias: Tensor[(64), float32], %features.5.squeeze.weight: Tensor[(32, 128, 1, 1), float32], %features.5.squeeze.bias: Tensor[(32), float32], %features.5.expand1x1.weight: Tensor[(128, 32, 1, 1), float32], %features.5.expand1x1.bias: Tensor[(128), float32], %features.5.expand3x3.weight: Tensor[(128, 32, 3, 3), float32], %features.5.expand3x3.bias: Tensor[(128), float32], %features.7.squeeze.weight: Tensor[(32, 256, 1, 1), float32], %features.7.squeeze.bias: Tensor[(32), float32], %features.7.expand1x1.weight: Tensor[(128, 32, 1, 1), float32], %features.7.expand1x1.bias: Tensor[(128), float32], %features.7.expand3x3.weight: Tensor[(128, 32, 3, 3), float32], %features.7.expand3x3.bias: Tensor[(128), float32], %features.8.squeeze.weight: Tensor[(48, 256, 1, 1), float32], %features.8.squeeze.bias: Tensor[(48), float32], %features.8.expand1x1.weight: Tensor[(192, 48, 1, 1), float32], %features.8.expand1x1.bias: Tensor[(192), float32], %features.8.expand3x3.weight: Tensor[(192, 48, 3, 3), float32], %features.8.expand3x3.bias: Tensor[(192), float32], %features.9.squeeze.weight: Tensor[(48, 384, 1, 1), float32], %features.9.squeeze.bias: Tensor[(48), float32], %features.9.expand1x1.weight: Tensor[(192, 48, 1, 1), float32], %features.9.expand1x1.bias: Tensor[(192), float32], %features.9.expand3x3.weight: Tensor[(192, 48, 3, 3), float32], %features.9.expand3x3.bias: Tensor[(192), float32], %features.10.squeeze.weight: Tensor[(64, 384, 1, 1), float32], %features.10.squeeze.bias: Tensor[(64), float32], %features.10.expand1x1.weight: Tensor[(256, 64, 1, 1), float32], %features.10.expand1x1.bias: Tensor[(256), float32], %features.10.expand3x3.weight: Tensor[(256, 64, 3, 3), float32], %features.10.expand3x3.bias: Tensor[(256), float32], %features.12.squeeze.weight: Tensor[(64, 512, 1, 1), float32], %features.12.squeeze.bias: Tensor[(64), float32], %features.12.expand1x1.weight: Tensor[(256, 64, 1, 1), float32], %features.12.expand1x1.bias: Tensor[(256), float32], %features.12.expand3x3.weight: Tensor[(256, 64, 3, 3), float32], %features.12.expand3x3.bias: Tensor[(256), float32], %classifier.1.weight: Tensor[(1000, 512, 1, 1), float32], %classifier.1.bias: Tensor[(1000), float32]) -> Tensor[(15, 1000), float32] {
  %0 = nn.conv2d(%data_0, %features.0.weight, strides=[2, 2], padding=[0, 0, 0, 0], channels=96, kernel_size=[7, 7]) /* ty=Tensor[(15, 96, 109, 109), float32] */;
  %1 = nn.bias_add(%0, %features.0.bias) /* ty=Tensor[(15, 96, 109, 109), float32] */;
  %2 = nn.relu(%1) /* ty=Tensor[(15, 96, 109, 109), float32] */;
  %3 = nn.max_pool2d(%2, pool_size=[3, 3], strides=[2, 2], padding=[0, 0, 0, 0], ceil_mode=True) /* ty=Tensor[(15, 96, 54, 54), float32] */;
  %4 = nn.conv2d(%3, %features.3.squeeze.weight, padding=[0, 0, 0, 0], channels=16, kernel_size=[1, 1]) /* ty=Tensor[(15, 16, 54, 54), float32] */;
  %5 = nn.bias_add(%4, %features.3.squeeze.bias) /* ty=Tensor[(15, 16, 54, 54), float32] */;
  %6 = nn.relu(%5) /* ty=Tensor[(15, 16, 54, 54), float32] */;
  %7 = nn.conv2d(%6, %features.3.expand1x1.weight, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1]) /* ty=Tensor[(15, 64, 54, 54), float32] */;
  %8 = nn.bias_add(%7, %features.3.expand1x1.bias) /* ty=Tensor[(15, 64, 54, 54), float32] */;
  %9 = nn.conv2d(%6, %features.3.expand3x3.weight, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(15, 64, 54, 54), float32] */;
  %10 = nn.bias_add(%9, %features.3.expand3x3.bias) /* ty=Tensor[(15, 64, 54, 54), float32] */;
  %11 = nn.relu(%8) /* ty=Tensor[(15, 64, 54, 54), float32] */;
  %12 = nn.relu(%10) /* ty=Tensor[(15, 64, 54, 54), float32] */;
  %13 = (%11, %12);
  %14 = concatenate(%13, axis=1) /* ty=Tensor[(15, 128, 54, 54), float32] */;
  %15 = nn.conv2d(%14, %features.4.squeeze.weight, padding=[0, 0, 0, 0], channels=16, kernel_size=[1, 1]) /* ty=Tensor[(15, 16, 54, 54), float32] */;
  %16 = nn.bias_add(%15, %features.4.squeeze.bias) /* ty=Tensor[(15, 16, 54, 54), float32] */;
  %17 = nn.relu(%16) /* ty=Tensor[(15, 16, 54, 54), float32] */;
  %18 = nn.conv2d(%17, %features.4.expand1x1.weight, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1]) /* ty=Tensor[(15, 64, 54, 54), float32] */;
  %19 = nn.bias_add(%18, %features.4.expand1x1.bias) /* ty=Tensor[(15, 64, 54, 54), float32] */;
  %20 = nn.conv2d(%17, %features.4.expand3x3.weight, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(15, 64, 54, 54), float32] */;
  %21 = nn.bias_add(%20, %features.4.expand3x3.bias) /* ty=Tensor[(15, 64, 54, 54), float32] */;
  %22 = nn.relu(%19) /* ty=Tensor[(15, 64, 54, 54), float32] */;
  %23 = nn.relu(%21) /* ty=Tensor[(15, 64, 54, 54), float32] */;
  %24 = (%22, %23);
  %25 = concatenate(%24, axis=1) /* ty=Tensor[(15, 128, 54, 54), float32] */;
  %26 = nn.conv2d(%25, %features.5.squeeze.weight, padding=[0, 0, 0, 0], channels=32, kernel_size=[1, 1]) /* ty=Tensor[(15, 32, 54, 54), float32] */;
  %27 = nn.bias_add(%26, %features.5.squeeze.bias) /* ty=Tensor[(15, 32, 54, 54), float32] */;
  %28 = nn.relu(%27) /* ty=Tensor[(15, 32, 54, 54), float32] */;
  %29 = nn.conv2d(%28, %features.5.expand1x1.weight, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]) /* ty=Tensor[(15, 128, 54, 54), float32] */;
  %30 = nn.bias_add(%29, %features.5.expand1x1.bias) /* ty=Tensor[(15, 128, 54, 54), float32] */;
  %31 = nn.conv2d(%28, %features.5.expand3x3.weight, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(15, 128, 54, 54), float32] */;
  %32 = nn.bias_add(%31, %features.5.expand3x3.bias) /* ty=Tensor[(15, 128, 54, 54), float32] */;
  %33 = nn.relu(%30) /* ty=Tensor[(15, 128, 54, 54), float32] */;
  %34 = nn.relu(%32) /* ty=Tensor[(15, 128, 54, 54), float32] */;
  %35 = (%33, %34);
  %36 = concatenate(%35, axis=1) /* ty=Tensor[(15, 256, 54, 54), float32] */;
  %37 = nn.max_pool2d(%36, pool_size=[3, 3], strides=[2, 2], padding=[0, 0, 0, 0], ceil_mode=True) /* ty=Tensor[(15, 256, 27, 27), float32] */;
  %38 = nn.conv2d(%37, %features.7.squeeze.weight, padding=[0, 0, 0, 0], channels=32, kernel_size=[1, 1]) /* ty=Tensor[(15, 32, 27, 27), float32] */;
  %39 = nn.bias_add(%38, %features.7.squeeze.bias) /* ty=Tensor[(15, 32, 27, 27), float32] */;
  %40 = nn.relu(%39) /* ty=Tensor[(15, 32, 27, 27), float32] */;
  %41 = nn.conv2d(%40, %features.7.expand1x1.weight, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]) /* ty=Tensor[(15, 128, 27, 27), float32] */;
  %42 = nn.bias_add(%41, %features.7.expand1x1.bias) /* ty=Tensor[(15, 128, 27, 27), float32] */;
  %43 = nn.conv2d(%40, %features.7.expand3x3.weight, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(15, 128, 27, 27), float32] */;
  %44 = nn.bias_add(%43, %features.7.expand3x3.bias) /* ty=Tensor[(15, 128, 27, 27), float32] */;
  %45 = nn.relu(%42) /* ty=Tensor[(15, 128, 27, 27), float32] */;
  %46 = nn.relu(%44) /* ty=Tensor[(15, 128, 27, 27), float32] */;
  %47 = (%45, %46);
  %48 = concatenate(%47, axis=1) /* ty=Tensor[(15, 256, 27, 27), float32] */;
  %49 = nn.conv2d(%48, %features.8.squeeze.weight, padding=[0, 0, 0, 0], channels=48, kernel_size=[1, 1]) /* ty=Tensor[(15, 48, 27, 27), float32] */;
  %50 = nn.bias_add(%49, %features.8.squeeze.bias) /* ty=Tensor[(15, 48, 27, 27), float32] */;
  %51 = nn.relu(%50) /* ty=Tensor[(15, 48, 27, 27), float32] */;
  %52 = nn.conv2d(%51, %features.8.expand1x1.weight, padding=[0, 0, 0, 0], channels=192, kernel_size=[1, 1]) /* ty=Tensor[(15, 192, 27, 27), float32] */;
  %53 = nn.bias_add(%52, %features.8.expand1x1.bias) /* ty=Tensor[(15, 192, 27, 27), float32] */;
  %54 = nn.conv2d(%51, %features.8.expand3x3.weight, padding=[1, 1, 1, 1], channels=192, kernel_size=[3, 3]) /* ty=Tensor[(15, 192, 27, 27), float32] */;
  %55 = nn.bias_add(%54, %features.8.expand3x3.bias) /* ty=Tensor[(15, 192, 27, 27), float32] */;
  %56 = nn.relu(%53) /* ty=Tensor[(15, 192, 27, 27), float32] */;
  %57 = nn.relu(%55) /* ty=Tensor[(15, 192, 27, 27), float32] */;
  %58 = (%56, %57);
  %59 = concatenate(%58, axis=1) /* ty=Tensor[(15, 384, 27, 27), float32] */;
  %60 = nn.conv2d(%59, %features.9.squeeze.weight, padding=[0, 0, 0, 0], channels=48, kernel_size=[1, 1]) /* ty=Tensor[(15, 48, 27, 27), float32] */;
  %61 = nn.bias_add(%60, %features.9.squeeze.bias) /* ty=Tensor[(15, 48, 27, 27), float32] */;
  %62 = nn.relu(%61) /* ty=Tensor[(15, 48, 27, 27), float32] */;
  %63 = nn.conv2d(%62, %features.9.expand1x1.weight, padding=[0, 0, 0, 0], channels=192, kernel_size=[1, 1]) /* ty=Tensor[(15, 192, 27, 27), float32] */;
  %64 = nn.bias_add(%63, %features.9.expand1x1.bias) /* ty=Tensor[(15, 192, 27, 27), float32] */;
  %65 = nn.conv2d(%62, %features.9.expand3x3.weight, padding=[1, 1, 1, 1], channels=192, kernel_size=[3, 3]) /* ty=Tensor[(15, 192, 27, 27), float32] */;
  %66 = nn.bias_add(%65, %features.9.expand3x3.bias) /* ty=Tensor[(15, 192, 27, 27), float32] */;
  %67 = nn.relu(%64) /* ty=Tensor[(15, 192, 27, 27), float32] */;
  %68 = nn.relu(%66) /* ty=Tensor[(15, 192, 27, 27), float32] */;
  %69 = (%67, %68);
  %70 = concatenate(%69, axis=1) /* ty=Tensor[(15, 384, 27, 27), float32] */;
  %71 = nn.conv2d(%70, %features.10.squeeze.weight, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1]) /* ty=Tensor[(15, 64, 27, 27), float32] */;
  %72 = nn.bias_add(%71, %features.10.squeeze.bias) /* ty=Tensor[(15, 64, 27, 27), float32] */;
  %73 = nn.relu(%72) /* ty=Tensor[(15, 64, 27, 27), float32] */;
  %74 = nn.conv2d(%73, %features.10.expand1x1.weight, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]) /* ty=Tensor[(15, 256, 27, 27), float32] */;
  %75 = nn.bias_add(%74, %features.10.expand1x1.bias) /* ty=Tensor[(15, 256, 27, 27), float32] */;
  %76 = nn.conv2d(%73, %features.10.expand3x3.weight, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(15, 256, 27, 27), float32] */;
  %77 = nn.bias_add(%76, %features.10.expand3x3.bias) /* ty=Tensor[(15, 256, 27, 27), float32] */;
  %78 = nn.relu(%75) /* ty=Tensor[(15, 256, 27, 27), float32] */;
  %79 = nn.relu(%77) /* ty=Tensor[(15, 256, 27, 27), float32] */;
  %80 = (%78, %79);
  %81 = concatenate(%80, axis=1) /* ty=Tensor[(15, 512, 27, 27), float32] */;
  %82 = nn.max_pool2d(%81, pool_size=[3, 3], strides=[2, 2], padding=[0, 0, 0, 0], ceil_mode=True) /* ty=Tensor[(15, 512, 13, 13), float32] */;
  %83 = nn.conv2d(%82, %features.12.squeeze.weight, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1]) /* ty=Tensor[(15, 64, 13, 13), float32] */;
  %84 = nn.bias_add(%83, %features.12.squeeze.bias) /* ty=Tensor[(15, 64, 13, 13), float32] */;
  %85 = nn.relu(%84) /* ty=Tensor[(15, 64, 13, 13), float32] */;
  %86 = nn.conv2d(%85, %features.12.expand1x1.weight, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]) /* ty=Tensor[(15, 256, 13, 13), float32] */;
  %87 = nn.bias_add(%86, %features.12.expand1x1.bias) /* ty=Tensor[(15, 256, 13, 13), float32] */;
  %88 = nn.conv2d(%85, %features.12.expand3x3.weight, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(15, 256, 13, 13), float32] */;
  %89 = nn.bias_add(%88, %features.12.expand3x3.bias) /* ty=Tensor[(15, 256, 13, 13), float32] */;
  %90 = nn.relu(%87) /* ty=Tensor[(15, 256, 13, 13), float32] */;
  %91 = nn.relu(%89) /* ty=Tensor[(15, 256, 13, 13), float32] */;
  %92 = (%90, %91);
  %93 = concatenate(%92, axis=1) /* ty=Tensor[(15, 512, 13, 13), float32] */;
  %94 = nn.conv2d(%93, %classifier.1.weight, padding=[0, 0, 0, 0], channels=1000, kernel_size=[1, 1]) /* ty=Tensor[(15, 1000, 13, 13), float32] */;
  %95 = nn.bias_add(%94, %classifier.1.bias) /* ty=Tensor[(15, 1000, 13, 13), float32] */;
  %96 = nn.relu(%95) /* ty=Tensor[(15, 1000, 13, 13), float32] */;
  %97 = nn.global_avg_pool2d(%96) /* ty=Tensor[(15, 1000, 1, 1), float32] */;
  nn.batch_flatten(%97) /* ty=Tensor[(15, 1000), float32] */
}