def @main(%data: Tensor[(15, 3, 224, 224), float32], %features.0.weight: Tensor[(64, 3, 3, 3), float32], %features.0.bias: Tensor[(64), float32], %features.2.weight: Tensor[(64, 64, 3, 3), float32], %features.2.bias: Tensor[(64), float32], %features.5.weight: Tensor[(128, 64, 3, 3), float32], %features.5.bias: Tensor[(128), float32], %features.7.weight: Tensor[(128, 128, 3, 3), float32], %features.7.bias: Tensor[(128), float32], %features.10.weight: Tensor[(256, 128, 3, 3), float32], %features.10.bias: Tensor[(256), float32], %features.12.weight: Tensor[(256, 256, 3, 3), float32], %features.12.bias: Tensor[(256), float32], %features.14.weight: Tensor[(256, 256, 3, 3), float32], %features.14.bias: Tensor[(256), float32], %features.16.weight: Tensor[(256, 256, 3, 3), float32], %features.16.bias: Tensor[(256), float32], %features.19.weight: Tensor[(512, 256, 3, 3), float32], %features.19.bias: Tensor[(512), float32], %features.21.weight: Tensor[(512, 512, 3, 3), float32], %features.21.bias: Tensor[(512), float32], %features.23.weight: Tensor[(512, 512, 3, 3), float32], %features.23.bias: Tensor[(512), float32], %features.25.weight: Tensor[(512, 512, 3, 3), float32], %features.25.bias: Tensor[(512), float32], %features.28.weight: Tensor[(512, 512, 3, 3), float32], %features.28.bias: Tensor[(512), float32], %features.30.weight: Tensor[(512, 512, 3, 3), float32], %features.30.bias: Tensor[(512), float32], %features.32.weight: Tensor[(512, 512, 3, 3), float32], %features.32.bias: Tensor[(512), float32], %features.34.weight: Tensor[(512, 512, 3, 3), float32], %features.34.bias: Tensor[(512), float32], %classifier.0.weight: Tensor[(4096, 25088), float32], %classifier.0.bias: Tensor[(4096), float32], %classifier.3.weight: Tensor[(4096, 4096), float32], %classifier.3.bias: Tensor[(4096), float32], %classifier.6.weight: Tensor[(1000, 4096), float32], %classifier.6.bias: Tensor[(1000), float32]) -> Tensor[(15, 1000), float32] {
  %0 = nn.conv2d(%data, %features.0.weight, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(15, 64, 224, 224), float32] */;
  %1 = nn.bias_add(%0, %features.0.bias) /* ty=Tensor[(15, 64, 224, 224), float32] */;
  %2 = nn.relu(%1) /* ty=Tensor[(15, 64, 224, 224), float32] */;
  %3 = nn.conv2d(%2, %features.2.weight, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(15, 64, 224, 224), float32] */;
  %4 = nn.bias_add(%3, %features.2.bias) /* ty=Tensor[(15, 64, 224, 224), float32] */;
  %5 = nn.relu(%4) /* ty=Tensor[(15, 64, 224, 224), float32] */;
  %6 = nn.max_pool2d(%5, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(15, 64, 112, 112), float32] */;
  %7 = nn.conv2d(%6, %features.5.weight, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(15, 128, 112, 112), float32] */;
  %8 = nn.bias_add(%7, %features.5.bias) /* ty=Tensor[(15, 128, 112, 112), float32] */;
  %9 = nn.relu(%8) /* ty=Tensor[(15, 128, 112, 112), float32] */;
  %10 = nn.conv2d(%9, %features.7.weight, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(15, 128, 112, 112), float32] */;
  %11 = nn.bias_add(%10, %features.7.bias) /* ty=Tensor[(15, 128, 112, 112), float32] */;
  %12 = nn.relu(%11) /* ty=Tensor[(15, 128, 112, 112), float32] */;
  %13 = nn.max_pool2d(%12, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(15, 128, 56, 56), float32] */;
  %14 = nn.conv2d(%13, %features.10.weight, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(15, 256, 56, 56), float32] */;
  %15 = nn.bias_add(%14, %features.10.bias) /* ty=Tensor[(15, 256, 56, 56), float32] */;
  %16 = nn.relu(%15) /* ty=Tensor[(15, 256, 56, 56), float32] */;
  %17 = nn.conv2d(%16, %features.12.weight, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(15, 256, 56, 56), float32] */;
  %18 = nn.bias_add(%17, %features.12.bias) /* ty=Tensor[(15, 256, 56, 56), float32] */;
  %19 = nn.relu(%18) /* ty=Tensor[(15, 256, 56, 56), float32] */;
  %20 = nn.conv2d(%19, %features.14.weight, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(15, 256, 56, 56), float32] */;
  %21 = nn.bias_add(%20, %features.14.bias) /* ty=Tensor[(15, 256, 56, 56), float32] */;
  %22 = nn.relu(%21) /* ty=Tensor[(15, 256, 56, 56), float32] */;
  %23 = nn.conv2d(%22, %features.16.weight, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(15, 256, 56, 56), float32] */;
  %24 = nn.bias_add(%23, %features.16.bias) /* ty=Tensor[(15, 256, 56, 56), float32] */;
  %25 = nn.relu(%24) /* ty=Tensor[(15, 256, 56, 56), float32] */;
  %26 = nn.max_pool2d(%25, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(15, 256, 28, 28), float32] */;
  %27 = nn.conv2d(%26, %features.19.weight, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(15, 512, 28, 28), float32] */;
  %28 = nn.bias_add(%27, %features.19.bias) /* ty=Tensor[(15, 512, 28, 28), float32] */;
  %29 = nn.relu(%28) /* ty=Tensor[(15, 512, 28, 28), float32] */;
  %30 = nn.conv2d(%29, %features.21.weight, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(15, 512, 28, 28), float32] */;
  %31 = nn.bias_add(%30, %features.21.bias) /* ty=Tensor[(15, 512, 28, 28), float32] */;
  %32 = nn.relu(%31) /* ty=Tensor[(15, 512, 28, 28), float32] */;
  %33 = nn.conv2d(%32, %features.23.weight, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(15, 512, 28, 28), float32] */;
  %34 = nn.bias_add(%33, %features.23.bias) /* ty=Tensor[(15, 512, 28, 28), float32] */;
  %35 = nn.relu(%34) /* ty=Tensor[(15, 512, 28, 28), float32] */;
  %36 = nn.conv2d(%35, %features.25.weight, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(15, 512, 28, 28), float32] */;
  %37 = nn.bias_add(%36, %features.25.bias) /* ty=Tensor[(15, 512, 28, 28), float32] */;
  %38 = nn.relu(%37) /* ty=Tensor[(15, 512, 28, 28), float32] */;
  %39 = nn.max_pool2d(%38, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(15, 512, 14, 14), float32] */;
  %40 = nn.conv2d(%39, %features.28.weight, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(15, 512, 14, 14), float32] */;
  %41 = nn.bias_add(%40, %features.28.bias) /* ty=Tensor[(15, 512, 14, 14), float32] */;
  %42 = nn.relu(%41) /* ty=Tensor[(15, 512, 14, 14), float32] */;
  %43 = nn.conv2d(%42, %features.30.weight, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(15, 512, 14, 14), float32] */;
  %44 = nn.bias_add(%43, %features.30.bias) /* ty=Tensor[(15, 512, 14, 14), float32] */;
  %45 = nn.relu(%44) /* ty=Tensor[(15, 512, 14, 14), float32] */;
  %46 = nn.conv2d(%45, %features.32.weight, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(15, 512, 14, 14), float32] */;
  %47 = nn.bias_add(%46, %features.32.bias) /* ty=Tensor[(15, 512, 14, 14), float32] */;
  %48 = nn.relu(%47) /* ty=Tensor[(15, 512, 14, 14), float32] */;
  %49 = nn.conv2d(%48, %features.34.weight, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(15, 512, 14, 14), float32] */;
  %50 = nn.bias_add(%49, %features.34.bias) /* ty=Tensor[(15, 512, 14, 14), float32] */;
  %51 = nn.relu(%50) /* ty=Tensor[(15, 512, 14, 14), float32] */;
  %52 = nn.max_pool2d(%51, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(15, 512, 7, 7), float32] */;
  %53 = nn.avg_pool2d(%52, pool_size=[1, 1], padding=[0, 0, 0, 0]) /* ty=Tensor[(15, 512, 7, 7), float32] */;
  %54 = nn.batch_flatten(%53) /* ty=Tensor[(15, 25088), float32] */;
  %55 = nn.batch_flatten(%54) /* ty=Tensor[(15, 25088), float32] */;
  %56 = nn.dense(%55, %classifier.0.weight, units=4096) /* ty=Tensor[(15, 4096), float32] */;
  %57 = multiply(1f /* ty=float32 */, %classifier.0.bias) /* ty=Tensor[(4096), float32] */;
  %58 = add(%56, %57) /* ty=Tensor[(15, 4096), float32] */;
  %59 = nn.relu(%58) /* ty=Tensor[(15, 4096), float32] */;
  %60 = nn.batch_flatten(%59) /* ty=Tensor[(15, 4096), float32] */;
  %61 = nn.dense(%60, %classifier.3.weight, units=4096) /* ty=Tensor[(15, 4096), float32] */;
  %62 = multiply(1f /* ty=float32 */, %classifier.3.bias) /* ty=Tensor[(4096), float32] */;
  %63 = add(%61, %62) /* ty=Tensor[(15, 4096), float32] */;
  %64 = nn.relu(%63) /* ty=Tensor[(15, 4096), float32] */;
  %65 = nn.batch_flatten(%64) /* ty=Tensor[(15, 4096), float32] */;
  %66 = nn.dense(%65, %classifier.6.weight, units=1000) /* ty=Tensor[(15, 1000), float32] */;
  %67 = multiply(1f /* ty=float32 */, %classifier.6.bias) /* ty=Tensor[(1000), float32] */;
  add(%66, %67) /* ty=Tensor[(15, 1000), float32] */
}