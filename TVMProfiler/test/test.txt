  %1 = nn.bias_add(%0, %conv1_bias) /* ty=Tensor[(32, 64, 112, 112), float32] */;
  %2 = nn.relu(%1) /* ty=Tensor[(32, 64, 112, 112), float32] */;
  %3 = nn.max_pool2d(%2, pool_size=[3, 3], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(32, 64, 55, 55), float32] */;
  %4 = nn.conv2d(%3, %fire1_input_conv_weight, padding=[0, 0, 0, 0], channels=16, kernel_size=[1, 1]) /* ty=Tensor[(32, 16, 55, 55), float32] */;
  %5 = nn.bias_add(%4, %fire1_input_conv_bias) /* ty=Tensor[(32, 16, 55, 55), float32] */;
  %6 = nn.relu(%5) /* ty=Tensor[(32, 16, 55, 55), float32] */;
  %7 = nn.conv2d(%6, %fire1_left_conv_weight, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1]) /* ty=Tensor[(32, 64, 55, 55), float32] */;
  %8 = nn.bias_add(%7, %fire1_left_conv_bias) /* ty=Tensor[(32, 64, 55, 55), float32] */;
  %9 = nn.conv2d(%6, %fire1_right_conv_weight, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(32, 64, 55, 55), float32] */;
  %10 = nn.bias_add(%9, %fire1_right_conv_bias) /* ty=Tensor[(32, 64, 55, 55), float32] */;
  %11 = nn.relu(%8) /* ty=Tensor[(32, 64, 55, 55), float32] */;
  %12 = nn.relu(%10) /* ty=Tensor[(32, 64, 55, 55), float32] */;
  %13 = (%11, %12);
  %14 = concatenate(%13, axis=1) /* ty=Tensor[(32, 128, 55, 55), float32] */;
  %15 = nn.conv2d(%14, %fire2_input_conv_weight, padding=[0, 0, 0, 0], channels=16, kernel_size=[1, 1]) /* ty=Tensor[(32, 16, 55, 55), float32] */;
  %16 = nn.bias_add(%15, %fire2_input_conv_bias) /* ty=Tensor[(32, 16, 55, 55), float32] */;
  %17 = nn.relu(%16) /* ty=Tensor[(32, 16, 55, 55), float32] */;
  %18 = nn.conv2d(%17, %fire2_left_conv_weight, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1]) /* ty=Tensor[(32, 64, 55, 55), float32] */;
  %19 = nn.bias_add(%18, %fire2_left_conv_bias) /* ty=Tensor[(32, 64, 55, 55), float32] */;
  %20 = nn.conv2d(%17, %fire2_right_conv_weight, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(32, 64, 55, 55), float32] */;
  %21 = nn.bias_add(%20, %fire2_right_conv_bias) /* ty=Tensor[(32, 64, 55, 55), float32] */;
  %22 = nn.relu(%19) /* ty=Tensor[(32, 64, 55, 55), float32] */;
  %23 = nn.relu(%21) /* ty=Tensor[(32, 64, 55, 55), float32] */;
  %24 = (%22, %23);
  %25 = concatenate(%24, axis=1) /* ty=Tensor[(32, 128, 55, 55), float32] */;
  %26 = nn.max_pool2d(%25, pool_size=[3, 3], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(32, 128, 27, 27), float32] */;
  %27 = nn.conv2d(%26, %fire3_input_conv_weight, padding=[0, 0, 0, 0], channels=32, kernel_size=[1, 1]) /* ty=Tensor[(32, 32, 27, 27), float32] */;
  %28 = nn.bias_add(%27, %fire3_input_conv_bias) /* ty=Tensor[(32, 32, 27, 27), float32] */;
  %29 = nn.relu(%28) /* ty=Tensor[(32, 32, 27, 27), float32] */;
  %30 = nn.conv2d(%29, %fire3_left_conv_weight, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]) /* ty=Tensor[(32, 128, 27, 27), float32] */;
  %31 = nn.bias_add(%30, %fire3_left_conv_bias) /* ty=Tensor[(32, 128, 27, 27), float32] */;
  %32 = nn.conv2d(%29, %fire3_right_conv_weight, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(32, 128, 27, 27), float32] */;
  %33 = nn.bias_add(%32, %fire3_right_conv_bias) /* ty=Tensor[(32, 128, 27, 27), float32] */;
  %34 = nn.relu(%31) /* ty=Tensor[(32, 128, 27, 27), float32] */;
  %35 = nn.relu(%33) /* ty=Tensor[(32, 128, 27, 27), float32] */;
  %36 = (%34, %35);
  %37 = concatenate(%36, axis=1) /* ty=Tensor[(32, 256, 27, 27), float32] */;
  %38 = nn.conv2d(%37, %fire4_input_conv_weight, padding=[0, 0, 0, 0], channels=32, kernel_size=[1, 1]) /* ty=Tensor[(32, 32, 27, 27), float32] */;
  %39 = nn.bias_add(%38, %fire4_input_conv_bias) /* ty=Tensor[(32, 32, 27, 27), float32] */;
  %40 = nn.relu(%39) /* ty=Tensor[(32, 32, 27, 27), float32] */;
  %41 = nn.conv2d(%40, %fire4_left_conv_weight, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]) /* ty=Tensor[(32, 128, 27, 27), float32] */;
  %42 = nn.bias_add(%41, %fire4_left_conv_bias) /* ty=Tensor[(32, 128, 27, 27), float32] */;
  %43 = nn.conv2d(%40, %fire4_right_conv_weight, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(32, 128, 27, 27), float32] */;
  %44 = nn.bias_add(%43, %fire4_right_conv_bias) /* ty=Tensor[(32, 128, 27, 27), float32] */;
  %45 = nn.relu(%42) /* ty=Tensor[(32, 128, 27, 27), float32] */;
  %46 = nn.relu(%44) /* ty=Tensor[(32, 128, 27, 27), float32] */;
  %47 = (%45, %46);
  %48 = concatenate(%47, axis=1) /* ty=Tensor[(32, 256, 27, 27), float32] */;
  %49 = nn.max_pool2d(%48, pool_size=[3, 3], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(32, 256, 13, 13), float32] */;
  %50 = nn.conv2d(%49, %fire5_input_conv_weight, padding=[0, 0, 0, 0], channels=48, kernel_size=[1, 1]) /* ty=Tensor[(32, 48, 13, 13), float32] */;
  %51 = nn.bias_add(%50, %fire5_input_conv_bias) /* ty=Tensor[(32, 48, 13, 13), float32] */;
  %52 = nn.relu(%51) /* ty=Tensor[(32, 48, 13, 13), float32] */;
  %53 = nn.conv2d(%52, %fire5_left_conv_weight, padding=[0, 0, 0, 0], channels=192, kernel_size=[1, 1]) /* ty=Tensor[(32, 192, 13, 13), float32] */;
  %54 = nn.bias_add(%53, %fire5_left_conv_bias) /* ty=Tensor[(32, 192, 13, 13), float32] */;
  %55 = nn.conv2d(%52, %fire5_right_conv_weight, padding=[1, 1, 1, 1], channels=192, kernel_size=[3, 3]) /* ty=Tensor[(32, 192, 13, 13), float32] */;
  %56 = nn.bias_add(%55, %fire5_right_conv_bias) /* ty=Tensor[(32, 192, 13, 13), float32] */;
  %57 = nn.relu(%54) /* ty=Tensor[(32, 192, 13, 13), float32] */;
  %58 = nn.relu(%56) /* ty=Tensor[(32, 192, 13, 13), float32] */;
  %59 = (%57, %58);
  %60 = concatenate(%59, axis=1) /* ty=Tensor[(32, 384, 13, 13), float32] */;
  %61 = nn.conv2d(%60, %fire6_input_conv_weight, padding=[0, 0, 0, 0], channels=48, kernel_size=[1, 1]) /* ty=Tensor[(32, 48, 13, 13), float32] */;
  %62 = nn.bias_add(%61, %fire6_input_conv_bias) /* ty=Tensor[(32, 48, 13, 13), float32] */;
  %63 = nn.relu(%62) /* ty=Tensor[(32, 48, 13, 13), float32] */;
  %64 = nn.conv2d(%63, %fire6_left_conv_weight, padding=[0, 0, 0, 0], channels=192, kernel_size=[1, 1]) /* ty=Tensor[(32, 192, 13, 13), float32] */;
  %65 = nn.bias_add(%64, %fire6_left_conv_bias) /* ty=Tensor[(32, 192, 13, 13), float32] */;
  %66 = nn.conv2d(%63, %fire6_right_conv_weight, padding=[1, 1, 1, 1], channels=192, kernel_size=[3, 3]) /* ty=Tensor[(32, 192, 13, 13), float32] */;
  %67 = nn.bias_add(%66, %fire6_right_conv_bias) /* ty=Tensor[(32, 192, 13, 13), float32] */;
  %68 = nn.relu(%65) /* ty=Tensor[(32, 192, 13, 13), float32] */;
  %69 = nn.relu(%67) /* ty=Tensor[(32, 192, 13, 13), float32] */;
  %70 = (%68, %69);
  %71 = concatenate(%70, axis=1) /* ty=Tensor[(32, 384, 13, 13), float32] */;
  %72 = nn.conv2d(%71, %fire7_input_conv_weight, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1]) /* ty=Tensor[(32, 64, 13, 13), float32] */;
  %73 = nn.bias_add(%72, %fire7_input_conv_bias) /* ty=Tensor[(32, 64, 13, 13), float32] */;
  %74 = nn.relu(%73) /* ty=Tensor[(32, 64, 13, 13), float32] */;
  %75 = nn.conv2d(%74, %fire7_left_conv_weight, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]) /* ty=Tensor[(32, 256, 13, 13), float32] */;
  %76 = nn.bias_add(%75, %fire7_left_conv_bias) /* ty=Tensor[(32, 256, 13, 13), float32] */;
  %77 = nn.conv2d(%74, %fire7_right_conv_weight, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(32, 256, 13, 13), float32] */;
  %78 = nn.bias_add(%77, %fire7_right_conv_bias) /* ty=Tensor[(32, 256, 13, 13), float32] */;
  %79 = nn.relu(%76) /* ty=Tensor[(32, 256, 13, 13), float32] */;
  %80 = nn.relu(%78) /* ty=Tensor[(32, 256, 13, 13), float32] */;
  %81 = (%79, %80);
  %82 = concatenate(%81, axis=1) /* ty=Tensor[(32, 512, 13, 13), float32] */;
  %83 = nn.conv2d(%82, %fire8_input_conv_weight, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1]) /* ty=Tensor[(32, 64, 13, 13), float32] */;
  %84 = nn.bias_add(%83, %fire8_input_conv_bias) /* ty=Tensor[(32, 64, 13, 13), float32] */;
  %85 = nn.relu(%84) /* ty=Tensor[(32, 64, 13, 13), float32] */;
  %86 = nn.conv2d(%85, %fire8_left_conv_weight, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]) /* ty=Tensor[(32, 256, 13, 13), float32] */;
  %87 = nn.bias_add(%86, %fire8_left_conv_bias) /* ty=Tensor[(32, 256, 13, 13), float32] */;
  %88 = nn.conv2d(%85, %fire8_right_conv_weight, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(32, 256, 13, 13), float32] */;
  %89 = nn.bias_add(%88, %fire8_right_conv_bias) /* ty=Tensor[(32, 256, 13, 13), float32] */;
  %90 = nn.relu(%87) /* ty=Tensor[(32, 256, 13, 13), float32] */;
  %91 = nn.relu(%89) /* ty=Tensor[(32, 256, 13, 13), float32] */;
  %92 = (%90, %91);
  %93 = concatenate(%92, axis=1) /* ty=Tensor[(32, 512, 13, 13), float32] */;
  %94 = nn.dropout(%93) /* ty=(Tensor[(32, 512, 13, 13), float32], Tensor[(32, 512, 13, 13), float32]) */;
  %95 = %94.0;
  %96 = nn.conv2d(%95, %conv_final_weight, padding=[0, 0, 0, 0], channels=1000, kernel_size=[1, 1]) /* ty=Tensor[(32, 1000, 13, 13), float32] */;
  %97 = nn.bias_add(%96, %conv_final_bias) /* ty=Tensor[(32, 1000, 13, 13), float32] */;
  %98 = nn.relu(%97) /* ty=Tensor[(32, 1000, 13, 13), float32] */;
  %99 = nn.global_avg_pool2d(%98) /* ty=Tensor[(32, 1000, 1, 1), float32] */;
  %100 = nn.batch_flatten(%99) /* ty=Tensor[(32, 1000), float32] */;
  nn.softmax(%100) /* ty=Tensor[(32, 1000), float32] */
}
