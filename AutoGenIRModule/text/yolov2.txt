def @main(%input.1: Tensor[(1, 3, 416, 416), float32], %models.0.bn1.bias: Tensor[(32), float32], %models.0.bn1.running_mean: Tensor[(32), float32], %models.0.bn1.running_var: Tensor[(32), float32], %models.0.bn1.weight: Tensor[(32), float32], %models.0.conv1.weight: Tensor[(32, 3, 3, 3), float32], %models.10.bn8.bias: Tensor[(256), float32], %models.10.bn8.running_mean: Tensor[(256), float32], %models.10.bn8.running_var: Tensor[(256), float32], %models.10.bn8.weight: Tensor[(256), float32], %models.10.conv8.weight: Tensor[(256, 128, 3, 3), float32], %models.12.bn9.bias: Tensor[(512), float32], %models.12.bn9.running_mean: Tensor[(512), float32], %models.12.bn9.running_var: Tensor[(512), float32], %models.12.bn9.weight: Tensor[(512), float32], %models.12.conv9.weight: Tensor[(512, 256, 3, 3), float32], %models.13.bn10.bias: Tensor[(256), float32], %models.13.bn10.running_mean: Tensor[(256), float32], %models.13.bn10.running_var: Tensor[(256), float32], %models.13.bn10.weight: Tensor[(256), float32], %models.13.conv10.weight: Tensor[(256, 512, 1, 1), float32], %models.14.bn11.bias: Tensor[(512), float32], %models.14.bn11.running_mean: Tensor[(512), float32], %models.14.bn11.running_var: Tensor[(512), float32], %models.14.bn11.weight: Tensor[(512), float32], %models.14.conv11.weight: Tensor[(512, 256, 3, 3), float32], %models.15.bn12.bias: Tensor[(256), float32], %models.15.bn12.running_mean: Tensor[(256), float32], %models.15.bn12.running_var: Tensor[(256), float32], %models.15.bn12.weight: Tensor[(256), float32], %models.15.conv12.weight: Tensor[(256, 512, 1, 1), float32], %models.16.bn13.bias: Tensor[(512), float32], %models.16.bn13.running_mean: Tensor[(512), float32], %models.16.bn13.running_var: Tensor[(512), float32], %models.16.bn13.weight: Tensor[(512), float32], %models.16.conv13.weight: Tensor[(512, 256, 3, 3), float32], %models.18.bn14.bias: Tensor[(1024), float32], %models.18.bn14.running_mean: Tensor[(1024), float32], %models.18.bn14.running_var: Tensor[(1024), float32], %models.18.bn14.weight: Tensor[(1024), float32], %models.18.conv14.weight: Tensor[(1024, 512, 3, 3), float32], %models.19.bn15.bias: Tensor[(512), float32], %models.19.bn15.running_mean: Tensor[(512), float32], %models.19.bn15.running_var: Tensor[(512), float32], %models.19.bn15.weight: Tensor[(512), float32], %models.19.conv15.weight: Tensor[(512, 1024, 1, 1), float32], %models.2.bn2.bias: Tensor[(64), float32], %models.2.bn2.running_mean: Tensor[(64), float32], %models.2.bn2.running_var: Tensor[(64), float32], %models.2.bn2.weight: Tensor[(64), float32], %models.2.conv2.weight: Tensor[(64, 32, 3, 3), float32], %models.20.bn16.bias: Tensor[(1024), float32], %models.20.bn16.running_mean: Tensor[(1024), float32], %models.20.bn16.running_var: Tensor[(1024), float32], %models.20.bn16.weight: Tensor[(1024), float32], %models.20.conv16.weight: Tensor[(1024, 512, 3, 3), float32], %models.21.bn17.bias: Tensor[(512), float32], %models.21.bn17.running_mean: Tensor[(512), float32], %models.21.bn17.running_var: Tensor[(512), float32], %models.21.bn17.weight: Tensor[(512), float32], %models.21.conv17.weight: Tensor[(512, 1024, 1, 1), float32], %models.22.bn18.bias: Tensor[(1024), float32], %models.22.bn18.running_mean: Tensor[(1024), float32], %models.22.bn18.running_var: Tensor[(1024), float32], %models.22.bn18.weight: Tensor[(1024), float32], %models.22.conv18.weight: Tensor[(1024, 512, 3, 3), float32], %models.23.bn19.bias: Tensor[(1024), float32], %models.23.bn19.running_mean: Tensor[(1024), float32], %models.23.bn19.running_var: Tensor[(1024), float32], %models.23.bn19.weight: Tensor[(1024), float32], %models.23.conv19.weight: Tensor[(1024, 1024, 3, 3), float32], %models.24.bn20.bias: Tensor[(1024), float32], %models.24.bn20.running_mean: Tensor[(1024), float32], %models.24.bn20.running_var: Tensor[(1024), float32], %models.24.bn20.weight: Tensor[(1024), float32], %models.24.conv20.weight: Tensor[(1024, 1024, 3, 3), float32], %models.26.bn21.bias: Tensor[(64), float32], %models.26.bn21.running_mean: Tensor[(64), float32], %models.26.bn21.running_var: Tensor[(64), float32], %models.26.bn21.weight: Tensor[(64), float32], %models.26.conv21.weight: Tensor[(64, 512, 1, 1), float32], %models.29.bn22.bias: Tensor[(1024), float32], %models.29.bn22.running_mean: Tensor[(1024), float32], %models.29.bn22.running_var: Tensor[(1024), float32], %models.29.bn22.weight: Tensor[(1024), float32], %models.29.conv22.weight: Tensor[(1024, 1280, 3, 3), float32], %models.30.conv23.bias: Tensor[(425), float32], %models.30.conv23.weight: Tensor[(425, 1024, 1, 1), float32], %models.4.bn3.bias: Tensor[(128), float32], %models.4.bn3.running_mean: Tensor[(128), float32], %models.4.bn3.running_var: Tensor[(128), float32], %models.4.bn3.weight: Tensor[(128), float32], %models.4.conv3.weight: Tensor[(128, 64, 3, 3), float32], %models.5.bn4.bias: Tensor[(64), float32], %models.5.bn4.running_mean: Tensor[(64), float32], %models.5.bn4.running_var: Tensor[(64), float32], %models.5.bn4.weight: Tensor[(64), float32], %models.5.conv4.weight: Tensor[(64, 128, 1, 1), float32], %models.6.bn5.bias: Tensor[(128), float32], %models.6.bn5.running_mean: Tensor[(128), float32], %models.6.bn5.running_var: Tensor[(128), float32], %models.6.bn5.weight: Tensor[(128), float32], %models.6.conv5.weight: Tensor[(128, 64, 3, 3), float32], %models.8.bn6.bias: Tensor[(256), float32], %models.8.bn6.running_mean: Tensor[(256), float32], %models.8.bn6.running_var: Tensor[(256), float32], %models.8.bn6.weight: Tensor[(256), float32], %models.8.conv6.weight: Tensor[(256, 128, 3, 3), float32], %models.9.bn7.bias: Tensor[(128), float32], %models.9.bn7.running_mean: Tensor[(128), float32], %models.9.bn7.running_var: Tensor[(128), float32], %models.9.bn7.weight: Tensor[(128), float32], %models.9.conv7.weight: Tensor[(128, 256, 1, 1), float32]) {
  %0 = nn.conv2d(%input.1, %models.0.conv1.weight, padding=[1, 1, 1, 1], channels=32, kernel_size=[3, 3]) /* ty=Tensor[(1, 32, 416, 416), float32] */;
  %1 = nn.batch_norm(%0, %models.0.bn1.weight, %models.0.bn1.bias, %models.0.bn1.running_mean, %models.0.bn1.running_var) /* ty=(Tensor[(1, 32, 416, 416), float32], Tensor[(32), float32], Tensor[(32), float32]) */;
  %2 = %1.0;
  %3 = nn.leaky_relu(%2, alpha=0.1f) /* ty=Tensor[(1, 32, 416, 416), float32] */;
  %4 = nn.max_pool2d(%3, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 32, 208, 208), float32] */;
  %5 = nn.conv2d(%4, %models.2.conv2.weight, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 208, 208), float32] */;
  %6 = nn.batch_norm(%5, %models.2.bn2.weight, %models.2.bn2.bias, %models.2.bn2.running_mean, %models.2.bn2.running_var) /* ty=(Tensor[(1, 64, 208, 208), float32], Tensor[(64), float32], Tensor[(64), float32]) */;
  %7 = %6.0;
  %8 = nn.leaky_relu(%7, alpha=0.1f) /* ty=Tensor[(1, 64, 208, 208), float32] */;
  %9 = nn.max_pool2d(%8, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 64, 104, 104), float32] */;
  %10 = nn.conv2d(%9, %models.4.conv3.weight, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 104, 104), float32] */;
  %11 = nn.batch_norm(%10, %models.4.bn3.weight, %models.4.bn3.bias, %models.4.bn3.running_mean, %models.4.bn3.running_var) /* ty=(Tensor[(1, 128, 104, 104), float32], Tensor[(128), float32], Tensor[(128), float32]) */;
  %12 = %11.0;
  %13 = nn.leaky_relu(%12, alpha=0.1f) /* ty=Tensor[(1, 128, 104, 104), float32] */;
  %14 = nn.conv2d(%13, %models.5.conv4.weight, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1]) /* ty=Tensor[(1, 64, 104, 104), float32] */;
  %15 = nn.batch_norm(%14, %models.5.bn4.weight, %models.5.bn4.bias, %models.5.bn4.running_mean, %models.5.bn4.running_var) /* ty=(Tensor[(1, 64, 104, 104), float32], Tensor[(64), float32], Tensor[(64), float32]) */;
  %16 = %15.0;
  %17 = nn.leaky_relu(%16, alpha=0.1f) /* ty=Tensor[(1, 64, 104, 104), float32] */;
  %18 = nn.conv2d(%17, %models.6.conv5.weight, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 104, 104), float32] */;
  %19 = nn.batch_norm(%18, %models.6.bn5.weight, %models.6.bn5.bias, %models.6.bn5.running_mean, %models.6.bn5.running_var) /* ty=(Tensor[(1, 128, 104, 104), float32], Tensor[(128), float32], Tensor[(128), float32]) */;
  %20 = %19.0;
  %21 = nn.leaky_relu(%20, alpha=0.1f) /* ty=Tensor[(1, 128, 104, 104), float32] */;
  %22 = nn.max_pool2d(%21, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 128, 52, 52), float32] */;
  %23 = nn.conv2d(%22, %models.8.conv6.weight, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 52, 52), float32] */;
  %24 = nn.batch_norm(%23, %models.8.bn6.weight, %models.8.bn6.bias, %models.8.bn6.running_mean, %models.8.bn6.running_var) /* ty=(Tensor[(1, 256, 52, 52), float32], Tensor[(256), float32], Tensor[(256), float32]) */;
  %25 = %24.0;
  %26 = nn.leaky_relu(%25, alpha=0.1f) /* ty=Tensor[(1, 256, 52, 52), float32] */;
  %27 = nn.conv2d(%26, %models.9.conv7.weight, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]) /* ty=Tensor[(1, 128, 52, 52), float32] */;
  %28 = nn.batch_norm(%27, %models.9.bn7.weight, %models.9.bn7.bias, %models.9.bn7.running_mean, %models.9.bn7.running_var) /* ty=(Tensor[(1, 128, 52, 52), float32], Tensor[(128), float32], Tensor[(128), float32]) */;
  %29 = %28.0;
  %30 = nn.leaky_relu(%29, alpha=0.1f) /* ty=Tensor[(1, 128, 52, 52), float32] */;
  %31 = nn.conv2d(%30, %models.10.conv8.weight, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 52, 52), float32] */;
  %32 = nn.batch_norm(%31, %models.10.bn8.weight, %models.10.bn8.bias, %models.10.bn8.running_mean, %models.10.bn8.running_var) /* ty=(Tensor[(1, 256, 52, 52), float32], Tensor[(256), float32], Tensor[(256), float32]) */;
  %33 = %32.0;
  %34 = nn.leaky_relu(%33, alpha=0.1f) /* ty=Tensor[(1, 256, 52, 52), float32] */;
  %35 = nn.max_pool2d(%34, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 256, 26, 26), float32] */;
  %36 = nn.conv2d(%35, %models.12.conv9.weight, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 26, 26), float32] */;
  %37 = nn.batch_norm(%36, %models.12.bn9.weight, %models.12.bn9.bias, %models.12.bn9.running_mean, %models.12.bn9.running_var) /* ty=(Tensor[(1, 512, 26, 26), float32], Tensor[(512), float32], Tensor[(512), float32]) */;
  %38 = %37.0;
  %39 = nn.leaky_relu(%38, alpha=0.1f) /* ty=Tensor[(1, 512, 26, 26), float32] */;
  %40 = nn.conv2d(%39, %models.13.conv10.weight, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]) /* ty=Tensor[(1, 256, 26, 26), float32] */;
  %41 = nn.batch_norm(%40, %models.13.bn10.weight, %models.13.bn10.bias, %models.13.bn10.running_mean, %models.13.bn10.running_var) /* ty=(Tensor[(1, 256, 26, 26), float32], Tensor[(256), float32], Tensor[(256), float32]) */;
  %42 = %41.0;
  %43 = nn.leaky_relu(%42, alpha=0.1f) /* ty=Tensor[(1, 256, 26, 26), float32] */;
  %44 = nn.conv2d(%43, %models.14.conv11.weight, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 26, 26), float32] */;
  %45 = nn.batch_norm(%44, %models.14.bn11.weight, %models.14.bn11.bias, %models.14.bn11.running_mean, %models.14.bn11.running_var) /* ty=(Tensor[(1, 512, 26, 26), float32], Tensor[(512), float32], Tensor[(512), float32]) */;
  %46 = %45.0;
  %47 = nn.leaky_relu(%46, alpha=0.1f) /* ty=Tensor[(1, 512, 26, 26), float32] */;
  %48 = nn.conv2d(%47, %models.15.conv12.weight, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]) /* ty=Tensor[(1, 256, 26, 26), float32] */;
  %49 = nn.batch_norm(%48, %models.15.bn12.weight, %models.15.bn12.bias, %models.15.bn12.running_mean, %models.15.bn12.running_var) /* ty=(Tensor[(1, 256, 26, 26), float32], Tensor[(256), float32], Tensor[(256), float32]) */;
  %50 = %49.0;
  %51 = nn.leaky_relu(%50, alpha=0.1f) /* ty=Tensor[(1, 256, 26, 26), float32] */;
  %52 = nn.conv2d(%51, %models.16.conv13.weight, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 26, 26), float32] */;
  %53 = nn.batch_norm(%52, %models.16.bn13.weight, %models.16.bn13.bias, %models.16.bn13.running_mean, %models.16.bn13.running_var) /* ty=(Tensor[(1, 512, 26, 26), float32], Tensor[(512), float32], Tensor[(512), float32]) */;
  %54 = %53.0;
  %55 = nn.leaky_relu(%54, alpha=0.1f) /* ty=Tensor[(1, 512, 26, 26), float32] */;
  %56 = nn.conv2d(%55, %models.26.conv21.weight, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1]) /* ty=Tensor[(1, 64, 26, 26), float32] */;
  %57 = nn.batch_norm(%56, %models.26.bn21.weight, %models.26.bn21.bias, %models.26.bn21.running_mean, %models.26.bn21.running_var) /* ty=(Tensor[(1, 64, 26, 26), float32], Tensor[(64), float32], Tensor[(64), float32]) */;
  %58 = %57.0;
  %59 = nn.leaky_relu(%58, alpha=0.1f) /* ty=Tensor[(1, 64, 26, 26), float32] */;
  %60 = reshape(%59, newshape=[1, 64, 13, 2, 13, 2]) /* ty=Tensor[(1, 64, 13, 2, 13, 2), float32] */;
  %61 = transpose(%60, axes=[0, 1, 2, 4, 3, 5]) /* ty=Tensor[(1, 64, 13, 13, 2, 2), float32] */;
  %62 = reshape(%61, newshape=[1, 64, 169, 4]) /* ty=Tensor[(1, 64, 169, 4), float32] */;
  %63 = transpose(%62, axes=[0, 1, 3, 2]) /* ty=Tensor[(1, 64, 4, 169), float32] */;
  %64 = reshape(%63, newshape=[1, 64, 4, 13, 13]) /* ty=Tensor[(1, 64, 4, 13, 13), float32] */;
  %65 = transpose(%64, axes=[0, 2, 1, 3, 4]) /* ty=Tensor[(1, 4, 64, 13, 13), float32] */;
  %66 = nn.max_pool2d(%55, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 512, 13, 13), float32] */;
  %67 = nn.conv2d(%66, %models.18.conv14.weight, padding=[1, 1, 1, 1], channels=1024, kernel_size=[3, 3]) /* ty=Tensor[(1, 1024, 13, 13), float32] */;
  %68 = nn.batch_norm(%67, %models.18.bn14.weight, %models.18.bn14.bias, %models.18.bn14.running_mean, %models.18.bn14.running_var) /* ty=(Tensor[(1, 1024, 13, 13), float32], Tensor[(1024), float32], Tensor[(1024), float32]) */;
  %69 = %68.0;
  %70 = nn.leaky_relu(%69, alpha=0.1f) /* ty=Tensor[(1, 1024, 13, 13), float32] */;
  %71 = nn.conv2d(%70, %models.19.conv15.weight, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]) /* ty=Tensor[(1, 512, 13, 13), float32] */;
  %72 = nn.batch_norm(%71, %models.19.bn15.weight, %models.19.bn15.bias, %models.19.bn15.running_mean, %models.19.bn15.running_var) /* ty=(Tensor[(1, 512, 13, 13), float32], Tensor[(512), float32], Tensor[(512), float32]) */;
  %73 = %72.0;
  %74 = nn.leaky_relu(%73, alpha=0.1f) /* ty=Tensor[(1, 512, 13, 13), float32] */;
  %75 = nn.conv2d(%74, %models.20.conv16.weight, padding=[1, 1, 1, 1], channels=1024, kernel_size=[3, 3]) /* ty=Tensor[(1, 1024, 13, 13), float32] */;
  %76 = nn.batch_norm(%75, %models.20.bn16.weight, %models.20.bn16.bias, %models.20.bn16.running_mean, %models.20.bn16.running_var) /* ty=(Tensor[(1, 1024, 13, 13), float32], Tensor[(1024), float32], Tensor[(1024), float32]) */;
  %77 = %76.0;
  %78 = nn.leaky_relu(%77, alpha=0.1f) /* ty=Tensor[(1, 1024, 13, 13), float32] */;
  %79 = nn.conv2d(%78, %models.21.conv17.weight, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]) /* ty=Tensor[(1, 512, 13, 13), float32] */;
  %80 = nn.batch_norm(%79, %models.21.bn17.weight, %models.21.bn17.bias, %models.21.bn17.running_mean, %models.21.bn17.running_var) /* ty=(Tensor[(1, 512, 13, 13), float32], Tensor[(512), float32], Tensor[(512), float32]) */;
  %81 = %80.0;
  %82 = nn.leaky_relu(%81, alpha=0.1f) /* ty=Tensor[(1, 512, 13, 13), float32] */;
  %83 = nn.conv2d(%82, %models.22.conv18.weight, padding=[1, 1, 1, 1], channels=1024, kernel_size=[3, 3]) /* ty=Tensor[(1, 1024, 13, 13), float32] */;
  %84 = nn.batch_norm(%83, %models.22.bn18.weight, %models.22.bn18.bias, %models.22.bn18.running_mean, %models.22.bn18.running_var) /* ty=(Tensor[(1, 1024, 13, 13), float32], Tensor[(1024), float32], Tensor[(1024), float32]) */;
  %85 = %84.0;
  %86 = nn.leaky_relu(%85, alpha=0.1f) /* ty=Tensor[(1, 1024, 13, 13), float32] */;
  %87 = nn.conv2d(%86, %models.23.conv19.weight, padding=[1, 1, 1, 1], channels=1024, kernel_size=[3, 3]) /* ty=Tensor[(1, 1024, 13, 13), float32] */;
  %88 = nn.batch_norm(%87, %models.23.bn19.weight, %models.23.bn19.bias, %models.23.bn19.running_mean, %models.23.bn19.running_var) /* ty=(Tensor[(1, 1024, 13, 13), float32], Tensor[(1024), float32], Tensor[(1024), float32]) */;
  %89 = %88.0;
  %90 = nn.leaky_relu(%89, alpha=0.1f) /* ty=Tensor[(1, 1024, 13, 13), float32] */;
  %91 = nn.conv2d(%90, %models.24.conv20.weight, padding=[1, 1, 1, 1], channels=1024, kernel_size=[3, 3]) /* ty=Tensor[(1, 1024, 13, 13), float32] */;
  %92 = nn.batch_norm(%91, %models.24.bn20.weight, %models.24.bn20.bias, %models.24.bn20.running_mean, %models.24.bn20.running_var) /* ty=(Tensor[(1, 1024, 13, 13), float32], Tensor[(1024), float32], Tensor[(1024), float32]) */;
  %93 = %92.0;
  %94 = reshape(%65, newshape=[1, 256, 13, 13]) /* ty=Tensor[(1, 256, 13, 13), float32] */;
  %95 = nn.leaky_relu(%93, alpha=0.1f) /* ty=Tensor[(1, 1024, 13, 13), float32] */;
  %96 = (%94, %95);
  %97 = concatenate(%96, axis=1) /* ty=Tensor[(1, 1280, 13, 13), float32] */;
  %98 = nn.conv2d(%97, %models.29.conv22.weight, padding=[1, 1, 1, 1], channels=1024, kernel_size=[3, 3]) /* ty=Tensor[(1, 1024, 13, 13), float32] */;
  %99 = nn.batch_norm(%98, %models.29.bn22.weight, %models.29.bn22.bias, %models.29.bn22.running_mean, %models.29.bn22.running_var) /* ty=(Tensor[(1, 1024, 13, 13), float32], Tensor[(1024), float32], Tensor[(1024), float32]) */;
  %100 = %99.0;
  %101 = nn.leaky_relu(%100, alpha=0.1f) /* ty=Tensor[(1, 1024, 13, 13), float32] */;
  %102 = nn.conv2d(%101, %models.30.conv23.weight, padding=[0, 0, 0, 0], channels=425, kernel_size=[1, 1]) /* ty=Tensor[(1, 425, 13, 13), float32] */;
  nn.bias_add(%102, %models.30.conv23.bias) /* ty=Tensor[(1, 425, 13, 13), float32] */
}