def @main(%fire8/expand3x3_w_0: Tensor[(256, 64, 3, 3), float32], %fire9/squeeze1x1_b_0: Tensor[(64), float32], %fire9/expand1x1_b_0: Tensor[(256), float32], %fire9/expand3x3_b_0: Tensor[(256), float32], %fire9/squeeze1x1_w_0: Tensor[(64, 512, 1, 1), float32], %fire8/expand1x1_b_0: Tensor[(256), float32], %fire9/expand3x3_w_0: Tensor[(256, 64, 3, 3), float32], %fire8/expand3x3_b_0: Tensor[(256), float32], %fire9/expand1x1_w_0: Tensor[(256, 64, 1, 1), float32], %conv10_w_0: Tensor[(1000, 512, 1, 1), float32], %fire8/expand1x1_w_0: Tensor[(256, 64, 1, 1), float32], %call_73: Tensor[(1, 64, 13, 13), float32], %conv10_b_0: Tensor[(1000), float32] {
  %74 = nn.relu(%73) /* ty=Tensor[(1, 64, 13, 13), float32] */;
  %75 = nn.conv2d(%74, %fire8/expand1x1_w_0, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]) /* ty=Tensor[(1, 256, 13, 13), float32] */;
  %76 = nn.bias_add(%75, %fire8/expand1x1_b_0) /* ty=Tensor[(1, 256, 13, 13), float32] */;
  %77 = nn.conv2d(%74, %fire8/expand3x3_w_0, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 13, 13), float32] */;
  %78 = nn.bias_add(%77, %fire8/expand3x3_b_0) /* ty=Tensor[(1, 256, 13, 13), float32] */;
  %79 = nn.relu(%76) /* ty=Tensor[(1, 256, 13, 13), float32] */;
  %80 = nn.relu(%78) /* ty=Tensor[(1, 256, 13, 13), float32] */;
  %81 = (%79, %80);
  %82 = concatenate(%81, axis=1) /* ty=Tensor[(1, 512, 13, 13), float32] */;
  %83 = nn.conv2d(%82, %fire9/squeeze1x1_w_0, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1]) /* ty=Tensor[(1, 64, 13, 13), float32] */;
  %84 = nn.bias_add(%83, %fire9/squeeze1x1_b_0) /* ty=Tensor[(1, 64, 13, 13), float32] */;
  %85 = nn.relu(%84) /* ty=Tensor[(1, 64, 13, 13), float32] */;
  %86 = nn.conv2d(%85, %fire9/expand1x1_w_0, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]) /* ty=Tensor[(1, 256, 13, 13), float32] */;
  %87 = nn.bias_add(%86, %fire9/expand1x1_b_0) /* ty=Tensor[(1, 256, 13, 13), float32] */;
  %88 = nn.conv2d(%85, %fire9/expand3x3_w_0, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 13, 13), float32] */;
  %89 = nn.bias_add(%88, %fire9/expand3x3_b_0) /* ty=Tensor[(1, 256, 13, 13), float32] */;
  %90 = nn.relu(%87) /* ty=Tensor[(1, 256, 13, 13), float32] */;
  %91 = nn.relu(%89) /* ty=Tensor[(1, 256, 13, 13), float32] */;
  %92 = (%90, %91);
  %93 = concatenate(%92, axis=1) /* ty=Tensor[(1, 512, 13, 13), float32] */;
  %94 = nn.dropout(%93) /* ty=(Tensor[(1, 512, 13, 13), float32], Tensor[(1, 512, 13, 13), float32]) */;
  %95 = %94.0;
  %96 = nn.conv2d(%95, %conv10_w_0, padding=[0, 0, 0, 0], channels=1000, kernel_size=[1, 1]) /* ty=Tensor[(1, 1000, 13, 13), float32] */;
  %97 = nn.bias_add(%96, %conv10_b_0) /* ty=Tensor[(1, 1000, 13, 13), float32] */;
  %98 = nn.relu(%97) /* ty=Tensor[(1, 1000, 13, 13), float32] */;
  %99 = nn.global_avg_pool2d(%98) /* ty=Tensor[(1, 1000, 1, 1), float32] */;
  %100 = max(%99, axis=[1, 2, 3], keepdims=True) /* ty=Tensor[(1, 1, 1, 1), float32] */;
  %101 = subtract(%99, %100) /* ty=Tensor[(1, 1000, 1, 1), float32] */;
  %102 = exp(%101) /* ty=Tensor[(1, 1000, 1, 1), float32] */;
  %103 = sum(%102, axis=[1, 2, 3], keepdims=True) /* ty=Tensor[(1, 1, 1, 1), float32] */;
  divide(%102, %103) /* ty=Tensor[(1, 1000, 1, 1), float32] */
}