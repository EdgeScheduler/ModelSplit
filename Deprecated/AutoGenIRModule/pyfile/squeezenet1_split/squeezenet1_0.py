import tvmfrom tvm import relay, IRModuleimport numpy as npdef SqueezeNetModule_0():    fire2_squeeze1x1_w_0 = relay.var("fire2/squeeze1x1_w_0", shape=(16, 64, 1, 1), dtype="float32")    fire2_expand1x1_b_0 = relay.var("fire2/expand1x1_b_0", shape=(64, ), dtype="float32")    fire3_squeeze1x1_w_0 = relay.var("fire3/squeeze1x1_w_0", shape=(16, 128, 1, 1), dtype="float32")    conv1_b_0 = relay.var("conv1_b_0", shape=(64, ), dtype="float32")    conv1_w_0 = relay.var("conv1_w_0", shape=(64, 3, 3, 3), dtype="float32")    fire3_expand3x3_w_0 = relay.var("fire3/expand3x3_w_0", shape=(64, 16, 3, 3), dtype="float32")    fire3_expand3x3_b_0 = relay.var("fire3/expand3x3_b_0", shape=(64, ), dtype="float32")    fire3_expand1x1_w_0 = relay.var("fire3/expand1x1_w_0", shape=(64, 16, 1, 1), dtype="float32")    fire2_expand1x1_w_0 = relay.var("fire2/expand1x1_w_0", shape=(64, 16, 1, 1), dtype="float32")    data_0 = relay.var("data_0", shape=(1, 3, 224, 224), dtype="float32")    fire2_expand3x3_b_0 = relay.var("fire2/expand3x3_b_0", shape=(64, ), dtype="float32")    fire3_expand1x1_b_0 = relay.var("fire3/expand1x1_b_0", shape=(64, ), dtype="float32")    fire3_squeeze1x1_b_0 = relay.var("fire3/squeeze1x1_b_0", shape=(16, ), dtype="float32")    fire2_squeeze1x1_b_0 = relay.var("fire2/squeeze1x1_b_0", shape=(16, ), dtype="float32")    fire2_expand3x3_w_0 = relay.var("fire2/expand3x3_w_0", shape=(64, 16, 3, 3), dtype="float32")    call_0 = relay.nn.conv2d(data_0, conv1_w_0, strides=[2, 2], padding=[0, 0, 0, 0], channels=64, kernel_size=[3, 3])
    call_1 = relay.nn.bias_add(call_0, conv1_b_0)
    call_2 = relay.nn.relu(call_1)
    call_3 = relay.nn.max_pool2d(call_2, pool_size=[3, 3], strides=[2, 2], padding=[0, 0, 0, 0])
    call_4 = relay.nn.conv2d(call_3, fire2_squeeze1x1_w_0, padding=[0, 0, 0, 0], channels=16, kernel_size=[1, 1])
    call_5 = relay.nn.bias_add(call_4, fire2_squeeze1x1_b_0)
    call_6 = relay.nn.relu(call_5)
    call_7 = relay.nn.conv2d(call_6, fire2_expand1x1_w_0, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1])
    call_8 = relay.nn.bias_add(call_7, fire2_expand1x1_b_0)
    call_9 = relay.nn.conv2d(call_6, fire2_expand3x3_w_0, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3])
    call_10 = relay.nn.bias_add(call_9, fire2_expand3x3_b_0)
    call_11 = relay.nn.relu(call_8)
    call_12 = relay.nn.relu(call_10)
    call_14 = relay.concatenate(relay.Tuple([call_11, call_12]), axis=1)
    call_15 = relay.nn.conv2d(call_14, fire3_squeeze1x1_w_0, padding=[0, 0, 0, 0], channels=16, kernel_size=[1, 1])
    call_16 = relay.nn.bias_add(call_15, fire3_squeeze1x1_b_0)
    call_17 = relay.nn.relu(call_16)
    call_18 = relay.nn.conv2d(call_17, fire3_expand1x1_w_0, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1])
    call_19 = relay.nn.bias_add(call_18, fire3_expand1x1_b_0)
    call_20 = relay.nn.conv2d(call_17, fire3_expand3x3_w_0, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3])
    call_21 = relay.nn.bias_add(call_20, fire3_expand3x3_b_0)
    call_22 = relay.nn.relu(call_19)
    call_23 = relay.nn.relu(call_21)
    call_output0 = relay.concatenate(relay.Tuple([call_22, call_23]), axis=1)
    return call_output0