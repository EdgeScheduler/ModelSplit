import tvmfrom tvm import relay, IRModuleimport numpy as npdef SqueezeNetModule_3():    fire8_expand3x3_w_0 = relay.var("fire8/expand3x3_w_0", shape=(256, 64, 3, 3), dtype="float32")    fire9_squeeze1x1_b_0 = relay.var("fire9/squeeze1x1_b_0", shape=(64, ), dtype="float32")    fire9_expand1x1_b_0 = relay.var("fire9/expand1x1_b_0", shape=(256, ), dtype="float32")    fire9_expand3x3_b_0 = relay.var("fire9/expand3x3_b_0", shape=(256, ), dtype="float32")    fire9_squeeze1x1_w_0 = relay.var("fire9/squeeze1x1_w_0", shape=(64, 512, 1, 1), dtype="float32")    fire8_expand1x1_b_0 = relay.var("fire8/expand1x1_b_0", shape=(256, ), dtype="float32")    fire9_expand3x3_w_0 = relay.var("fire9/expand3x3_w_0", shape=(256, 64, 3, 3), dtype="float32")    fire8_expand3x3_b_0 = relay.var("fire8/expand3x3_b_0", shape=(256, ), dtype="float32")    fire9_expand1x1_w_0 = relay.var("fire9/expand1x1_w_0", shape=(256, 64, 1, 1), dtype="float32")    conv10_w_0 = relay.var("conv10_w_0", shape=(1000, 512, 1, 1), dtype="float32")    fire8_expand1x1_w_0 = relay.var("fire8/expand1x1_w_0", shape=(256, 64, 1, 1), dtype="float32")    call_73 = relay.var("call_73", shape=(1, 64, 13, 13), dtype="float32")    conv10_b_0 = relay.var("conv10_b_0", shape=(1000, ), dtype="float32")    call_74 = relay.nn.relu(call_73)
    call_75 = relay.nn.conv2d(call_74, fire8_expand1x1_w_0, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1])
    call_76 = relay.nn.bias_add(call_75, fire8_expand1x1_b_0)
    call_77 = relay.nn.conv2d(call_74, fire8_expand3x3_w_0, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3])
    call_78 = relay.nn.bias_add(call_77, fire8_expand3x3_b_0)
    call_79 = relay.nn.relu(call_76)
    call_80 = relay.nn.relu(call_78)
    call_82 = relay.concatenate(relay.Tuple([call_79, call_80]), axis=1)
    call_83 = relay.nn.conv2d(call_82, fire9_squeeze1x1_w_0, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1])
    call_84 = relay.nn.bias_add(call_83, fire9_squeeze1x1_b_0)
    call_85 = relay.nn.relu(call_84)
    call_86 = relay.nn.conv2d(call_85, fire9_expand1x1_w_0, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1])
    call_87 = relay.nn.bias_add(call_86, fire9_expand1x1_b_0)
    call_88 = relay.nn.conv2d(call_85, fire9_expand3x3_w_0, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3])
    call_89 = relay.nn.bias_add(call_88, fire9_expand3x3_b_0)
    call_90 = relay.nn.relu(call_87)
    call_91 = relay.nn.relu(call_89)
    call_93 = relay.concatenate(relay.Tuple([call_90, call_91]), axis=1)
    call_94_0 = relay.nn.dropout(call_93)
    call_96 = relay.nn.conv2d(call_94_0, conv10_w_0, padding=[0, 0, 0, 0], channels=1000, kernel_size=[1, 1])
    call_97 = relay.nn.bias_add(call_96, conv10_b_0)
    call_98 = relay.nn.relu(call_97)
    call_99 = relay.nn.global_avg_pool2d(call_98)
    call_100 = relay.max(call_99, axis=[1, 2, 3], keepdims=True)
    call_101 = relay.subtract(call_99, call_100)
    call_102 = relay.exp(call_101)
    call_103 = relay.sum(call_102, axis=[1, 2, 3], keepdims=True)
    call_output0 = relay.divide(call_102, call_103)
    return call_output0